services:
  app:
    image: mymyhoney/greg2-app:latest
    container_name: rag_app
    ports:
      - "8501:8501"
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - ENV_FILE=.env
      - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - COLLECTION_NAME=${COLLECTION_NAME:-docs}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-BAAI/bge-m3}
      - RERANK_MODEL=${RERANK_MODEL:-BAAI/bge-reranker-base}
      - LLM_MODEL=${LLM_MODEL:-llama3.1:8b}
      - DATA_ROOT=/data
    volumes:
      - ./data:/data
      - ./.env:/.env:ro
    depends_on:
      - qdrant
      - ollama
    command: ["streamlit", "run", "/app/main.py", "--server.port=8501", "--server.address=0.0.0.0"]

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
    volumes:
      - ./data/qdrant:/qdrant/storage

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "ollama serve &
      sleep 2 &&
      ollama pull ${LLM_MODEL:-deepseek-r1} &&
      wait"
